{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "18cycKETFBcZBCbjVjWW9KrkACvDP9-6B",
      "authorship_tag": "ABX9TyPQ2gzkNm5553WSBKsUMqV2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KitHaywood/Crypto-Backtester/blob/main/VectorisedBacktesting.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "anxVIZD4UiQJ"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as _np\n",
        "from scipy.optimize import curve_fit\n",
        "from scipy.misc import derivative\n",
        "import yfinance as yf\n",
        "import random as rd\n",
        "from datetime import datetime, timedelta\n",
        "from tqdm import tqdm\n",
        "import time\n",
        "import itertools\n",
        "import numpy as np\n",
        "from autograd import grad, jacobian\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def _get_1y_hourly_data(instr: str) -> pd.DataFrame:\n",
        "\n",
        "    t = yf.Ticker(instr)\n",
        "    dr = pd.date_range(\n",
        "        start=datetime.today()-timedelta(days=365),\n",
        "        end=datetime.today(),\n",
        "        freq='5D'\n",
        "    )\n",
        "\n",
        "    intervals = [(dr[i],dr[i+1]) for i in range(len(dr)-1)]\n",
        "    df = pd.DataFrame()\n",
        "\n",
        "    for s,e in tqdm(intervals):\n",
        "\n",
        "        _df = yf.download(\n",
        "            tickers=instr,\n",
        "            start=s,\n",
        "            end=e,\n",
        "            interval='1h'\n",
        "        )\n",
        "\n",
        "    #  period=\"5d\", interval=\"1m\"\n",
        "        df = pd.concat([df,_df])\n",
        "        time.sleep(0)\n",
        "\n",
        "    return df\n",
        "\n",
        "instr = 'TSLA'\n",
        "df = _get_1y_hourly_data(instr)\n",
        "df = df.drop(['Adj Close','Volume'],axis=1)\n",
        "df.index = df.index.tz_localize(None)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hjru0n_Rhxd8",
        "outputId": "d84332ef-f0a4-43dc-910f-25dd41e1af1a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "100%|██████████| 73/73 [00:14<00:00,  4.90it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import itertools\n",
        "outdf = pd.DataFrame()\n",
        "\n",
        "#################################################################################\n",
        "# Creating Random 1 Minute Data using highs and lows at random minutes in the hour\n",
        "#################################################################################\n",
        "\n",
        "for i,r in tqdm(df.iterrows()):\n",
        "\n",
        "    hidx,lidx = rd.sample(list(range(2,59)),2)\n",
        "\n",
        "    if hidx > lidx:\n",
        "        early = sorted([round(rd.uniform(r['Open'],r['Low']),4) for _ in range(lidx-1)])[::-1]\n",
        "        mid = sorted([round(rd.uniform(r['Low'],r['High']),4) for _ in range(hidx-lidx-1)])\n",
        "        late = sorted([round(rd.uniform(r['Low'],r['Close']),4) for _ in range(59-hidx)])[::-1]\n",
        "    else:\n",
        "        early = sorted([round(rd.uniform(r['Open'],r['High']),4) for _ in range(hidx-1)])\n",
        "        mid = sorted([round(rd.uniform(r['Low'],r['High']),4) for _ in range(lidx-hidx-1)])[::-1]\n",
        "        late = sorted([round(rd.uniform(r['High'],r['Close']),4) for _ in range(59-lidx)])\n",
        "\n",
        "    new_vals = list(itertools.chain(early, mid, late))\n",
        "\n",
        "    new_vals.insert(lidx,r['Low'])\n",
        "    new_vals.insert(hidx,r['High'])\n",
        "\n",
        "    _df = pd.DataFrame(\n",
        "        new_vals,\n",
        "        columns=['Close'],\n",
        "        index=pd.date_range(\n",
        "            start=r.name,\n",
        "            end=r.name + timedelta(minutes=58),\n",
        "            freq='1min'\n",
        "        ))\n",
        "\n",
        "    outdf = pd.concat([outdf,_df])\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IUmzqK_raxSE",
        "outputId": "ea49d570-18de-43da-9844-dd997c198432"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "1746it [00:10, 165.51it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "O3yBdNBck671"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "outdf.to_csv(\"/content/drive/MyDrive/DATA/tsla_data.csv\")"
      ],
      "metadata": {
        "id": "j2D5bBvlezHT"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from autograd import jacobian\n",
        "import numba as nb\n",
        "import time\n",
        "import warnings\n",
        "from typing import Callable, Tuple\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "\n",
        "\n",
        "def func(x: float ,*a: list[float]) -> float:\n",
        "    return a[0] + a[1] * np.exp(x) + a[2] * np.exp(x)\n",
        "\n",
        "def strides(a, L, S=1 ):  # Window len = L, Stride len/stepsize = S\n",
        "    nrows = ((a.size-L)//S)+1\n",
        "    n = a.strides[0]\n",
        "    return _np.lib.stride_tricks.as_strided(a, shape=(nrows,L), strides=(S*n,n))\n",
        "\n",
        "def normalize_negative_one(a):\n",
        "    div = np.max(a,axis=1) - np.min(a,axis=1)\n",
        "    div = np.dstack([div]*a.shape[1])[0]\n",
        "    normalized_input = (a - np.dstack([np.min(a,axis=1)] * a.shape[1])[0]) / div\n",
        "    return (2 * normalized_input) - 1\n",
        "\n",
        "def num_trades(s):\n",
        "    return (np.diff(s)!=0).sum()\n",
        "\n",
        "def _mdd(a):\n",
        "    acc_max = np.maximum.accumulate(a)\n",
        "    return (a - acc_max).min()\n",
        "\n",
        "def _calc_nt_score(x: int, sensible_nt: int) -> float:\n",
        "    if x == 0:\n",
        "        return 0\n",
        "    elif x < sensible_nt:\n",
        "        return abs(1 - (sensible_nt/x))\n",
        "    elif x > sensible_nt:\n",
        "        return 1 / (x/sensible_nt)**2\n",
        "    elif x == sensible_nt:\n",
        "        return 1\n",
        "\n",
        "def calc_all_indicators(prices: pd.DataFrame, windows: np.ndarray, btdepth: int) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    RETURNS:\n",
        "    indicator: np.ndarray -> (len(windows) ** 2, 2, btdepth)\n",
        "    thresholds: np.ndarray -> (len(windows) ** 2, 2 btdepth)\n",
        "    \"\"\"\n",
        "    der1 = {}\n",
        "    der2 = {}\n",
        "\n",
        "    vals = prices['Close'].to_numpy()\n",
        "\n",
        "    for a in tqdm(windows):\n",
        "\n",
        "        y =  np.linspace(0,1,a)\n",
        "        s = normalize_negative_one(strides(vals,int(a),1))\n",
        "        coefs = [curve_fit(func, x,y,p0=[1.]*3,ftol=5e-1)[0] for x in s]\n",
        "        der1[a] =  [derivative(func, 1, dx=0.001,args=c, n=1) for c in coefs][-btdepth:]\n",
        "        der2[a] =  [derivative(func, 1, dx=0.001,args=c, n=2) for c in coefs][-btdepth:]\n",
        "\n",
        "    d1 = np.array([list(der1.values())])[0]\n",
        "    d2 = np.array([list(der2.values())])[0]\n",
        "\n",
        "    ind = np.array(list(itertools.product(d1,d2)))\n",
        "    threshold = np.linspace(0,np.max(ind.flat),100)\n",
        "    threshold = np.array(list(itertools.product(threshold,threshold)))\n",
        "    t = np.repeat(threshold[:,:,np.newaxis],ind.shape[-1],axis=2)\n",
        "    return ind, t, coefs\n",
        "\n",
        "def calc_sig(ind: np.ndarray, thresh: np.ndarray,axis: int = 1) -> np.array:\n",
        "    sig = np.where(ind > thresh, 1, 0)\n",
        "    sig = np.where(ind < -thresh, -1, sig)\n",
        "    sig = np.sum(sig,axis=axis)\n",
        "    conds = [sig == 2, sig == -2]\n",
        "    opt = [1,-1]\n",
        "    sig = np.select(conds, opt, default=0)\n",
        "    return sig\n",
        "\n",
        "\n",
        "def calc_rets(prices: np.ndarray, sig: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:\n",
        "    p_returns = np.diff(prices)/prices[0]\n",
        "    p_returns = np.pad(p_returns,(0,1))\n",
        "    p_cum_returns = np.cumsum(p_returns)\n",
        "    sig_rets = sig * p_returns\n",
        "    cr = np.cumsum(sig_rets,axis=1)\n",
        "    return sig_rets, cr\n",
        "\n",
        "\n",
        "def run_opter_bt(prices: np.ndarray, ind: np.ndarray, thresh: np.ndarray, wghts: np.ndarray) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    TODO: Signal Lag not accounted for - 20 consecutive signals required -- tricky\n",
        "    \"\"\"\n",
        "\n",
        "    # Signal Calculation\n",
        "    sig = calc_sig(ind, thresh)\n",
        "    print(sig.shape)\n",
        "    print(prices.shape)\n",
        "    sig_rets, cr = calc_rets(prices,sig)\n",
        "\n",
        "    # BT Results\n",
        "    sharpe = (np.mean(sig_rets,axis=1) / np.std(sig_rets,axis=1)) * np.sqrt(sig.shape[-1])\n",
        "    sharpe = np.nan_to_num(sharpe)\n",
        "    mdd = np.apply_along_axis(_mdd,1,cr)\n",
        "    min_eq = np.apply_along_axis(np.min,1, cr)\n",
        "    max_eq = np.apply_along_axis(np.max,1, cr)\n",
        "    ntrad = np.apply_along_axis(num_trades,1,sig_rets)\n",
        "    ntrad = ntrad.astype(int)\n",
        "\n",
        "    # Individual optimums\n",
        "    res = np.stack((sharpe,mdd,min_eq,max_eq,ntrad)).T\n",
        "    best_sharpe = np.max(res[:,0])\n",
        "    best_dd = np.max(res[:,1])\n",
        "    best_min_eq = np.max(res[:,2])\n",
        "    best_max_eq = np.max(res[:,3])\n",
        "    sensible_numtrades = np.median(res[:,4])\n",
        "\n",
        "    # individual scores\n",
        "    sharpe_score = 1 - ((best_sharpe - sharpe)/best_sharpe)\n",
        "    dd_score = np.abs(best_dd + mdd)\n",
        "    min_eq_score = 1 - (best_min_eq + min_eq)\n",
        "    max_eq_score = 1 - (best_max_eq - max_eq)\n",
        "    sensible_nt = np.median(ntrad)\n",
        "    _nt_scores = [_calc_nt_score(x,sensible_nt) for x in ntrad]\n",
        "\n",
        "    scores = np.stack((sharpe_score, dd_score, min_eq_score, max_eq_score, _nt_scores)).T\n",
        "    scores = np.sum(wghts * scores, axis=1)\n",
        "    best_score = np.max(scores)\n",
        "\n",
        "    return best_score, scores, res\n"
      ],
      "metadata": {
        "id": "D9JIkBl6v9Lw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Callable\n",
        "\n",
        "def fit(x: np.ndarray,y: np.ndarray) -> np.ndarray:\n",
        "    \"\"\"Perform single curve_fit on single stride for windowlength x\"\"\"\n",
        "    return curve_fit(func, x, y,p0=[0.]*3,ftol=5e-1)[0]\n",
        "\n",
        "def get_deriv(cfs: np.array, num: int) -> float:\n",
        "    return derivative(func,1,dx=0.001,args=cfs, n=num)\n",
        "\n",
        "def calc_full_ind_future(prices: np.ndarray, win1: int, win2: int) -> np.ndarray:\n",
        "\n",
        "    s = list(zip(\n",
        "        normalize_negative_one(strides(prices,win1,1)),\n",
        "        normalize_negative_one(strides(prices,win2,1))\n",
        "    ))\n",
        "\n",
        "    y_win1 = np.linspace(0,1,win1)\n",
        "    y_win2 = np.linspace(0,1,win2)\n",
        "\n",
        "    cfs = [(fit(s1,y_win1),fit(s2,y_win2)) for s1,s2 in tqdm(s)]\n",
        "    inds = [(get_deriv(cfs1,num=1),get_deriv(cfs2,num=2)) for cfs1,cfs2 in cfs]\n",
        "\n",
        "    return np.array(inds).T\n",
        "\n",
        "def calc_perf_future(prices: np.ndarray, win1: int, win2: int, thresh1: float, thresh2: float) -> np.ndarray:\n",
        "\n",
        "    ind = calc_full_ind_future(prices, win1, win2)\n",
        "    ts = np.array([thresh1,thresh2])\n",
        "    ts = np.repeat(ts[:,np.newaxis],ind.shape[-1],axis=1)\n",
        "    sig = calc_sig(ind, ts, axis=0)\n",
        "    sup_sig = np.roll(sig,20)\n",
        "    sup_sig = np.hstack((np.zeros(20),sup_sig[20:]))\n",
        "    trade_sig = sig+sup_sig\n",
        "    conds = [trade_sig == 2, trade_sig == -2]\n",
        "    opt = [1,-1]\n",
        "\n",
        "    full_sig = np.select(conds, opt, default=0)\n",
        "\n",
        "    # cr, rets = calc_rets(prices, full_sig)\n",
        "\n",
        "    return prices, full_sig\n",
        "\n",
        "def calc_indgrid_and_bt(prices: np.array, windows: np.array, btdepth):\n",
        "    \"\"\"\n",
        "    Creates N x N windows (combs)\n",
        "\n",
        "    Creates N**2 x 2 x btepth - indicator grid\n",
        "    \"\"\"\n",
        "    win_combs = np.array(list(itertools.product(windows,windows)))\n",
        "    bt_end = prices.index[-1]\n",
        "\n",
        "    ind, thresh,coefs = calc_all_indicators(\n",
        "        prices = prices,\n",
        "        windows = windows,\n",
        "        btdepth = btdepth,\n",
        "        )\n",
        "\n",
        "    bt_prices = outdf['Close'].asfreq('1H').ffill().iloc[max(windows):(max(windows)+1200)].values\n",
        "    best_score, scores, res = run_opter_bt(bt_prices,ind, thresh,wghts=np.array([1,0,0,2,0]))\n",
        "    win1, win2 = win_combs[np.where(scores == best_score)[0][0]]\n",
        "    t1, t2 = thresh[np.where(scores == best_score)[0][0]][:,0]\n",
        "    return  win1, win2, t1, t2, bt_end\n",
        "\n",
        "\n",
        "def recursive_full_run(prices: pd.DataFrame) -> np.ndarray:\n",
        "    # Takes the prices\n",
        "\n",
        "    # Calculates the indicators and threshold grid for first run at index 0 -> (btdepth + max(win))\n",
        "\n",
        "    btdepth = 1200\n",
        "    windows = np.linspace(200,400,100,dtype=int)\n",
        "    bt_prices = prices.asfreq('1H').ffill().iloc[:(btdepth+max(windows))]\n",
        "    win1, win2, t1, t2, bt_end = calc_indgrid_and_bt(bt_prices,windows, btdepth)\n",
        "\n",
        "    # Next Run\n",
        "    prices = prices.loc[bt_end:bt_end+timedelta(hours=int(btdepth*0.35))].Close.values\n",
        "    prices, full_sig = calc_perf_future(prices, win1, win2, t1, t2)\n",
        "\n",
        "    return  prices, full_sig\n",
        "\n",
        "prices, full_sig = recursive_full_run(prices)"
      ],
      "metadata": {
        "id": "qBxVARegqk2J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ca57a3a-de15-4425-d32b-45cb5a0a2271"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [01:23<00:00,  1.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10000, 1200)\n",
            "(1200,)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 150871/150871 [02:52<00:00, 873.16it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prices = outdf.asfreq(\"10S\").interpolate()\n",
        "\n",
        "btdepth = 1200\n",
        "windows = np.linspace(200,400,100,dtype=int)\n",
        "\n",
        "bt_prices = prices.asfreq('1H').ffill().iloc[:(btdepth+max(windows))]\n",
        "win1, win2, t1, t2, bt_end = calc_indgrid_and_bt(bt_prices,windows, btdepth)\n",
        "\n",
        "# Next Run\n",
        "_ind_prices = prices.loc[bt_end:bt_end+timedelta(hours=int(btdepth*0.35))].iloc[:-max([win1,win2])].Close.values\n",
        "_prices = prices.loc[bt_end:bt_end+timedelta(hours=int(btdepth*0.35))].Close.values\n",
        "ind = calc_full_ind_future(_ind_prices, win1, win2)\n",
        "\n",
        "ts = np.array([t1,t2])\n",
        "ts = np.repeat(ts[:,np.newaxis],ind.shape[-1],axis=1)\n",
        "\n",
        "sig = calc_sig(ind, ts, axis=0)\n",
        "sup_sig = np.roll(sig,20)\n",
        "sup_sig = np.hstack((np.zeros(20),sup_sig[20:]))\n",
        "trade_sig = sig + sup_sig\n",
        "conds = [trade_sig == 2, trade_sig == -2]\n",
        "opt = [1,-1]\n",
        "full_sig = np.select(conds, opt, default=0)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BC6C_WnKnf0I",
        "outputId": "5cd0fe96-7ff5-4ad9-d9e7-c9cf33c45d64"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [01:26<00:00,  1.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10000, 1200)\n",
            "(1200,)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 150540/150540 [03:03<00:00, 822.07it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"_prices\",_prices.shape)\n",
        "print(\"ind.shape\",ind.shape)\n",
        "print(\"trade_sig\",trade_sig.shape)\n",
        "print(\"full_sig.shape\",full_sig.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iViBDOYV7Atz",
        "outputId": "618f18d9-6e9a-4802-9d91-0fab39e69ec6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "_prices (150870,)\n",
            "ind.shape (2, 150540)\n",
            "trade_sig (150540,)\n",
            "full_sig.shape (150540,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oi-EvwSH_VQz",
        "outputId": "b5c56e92-5fd9-4bb0-d8ed-303cc25f86d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(150540,)"
            ]
          },
          "metadata": {},
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cr, rets = calc_rets(_prices, full_sig)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        },
        "id": "9km8Ntji_RmH",
        "outputId": "74160a47-0a46-48df-9500-0ef1cc5c9249"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "operands could not be broadcast together with shapes (150540,) (150870,) ",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-100-25c70230075d>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalc_rets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfull_sig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-70-295fe67326cb>\u001b[0m in \u001b[0;36mcalc_rets\u001b[0;34m(prices, sig)\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0mp_returns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp_returns\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[0mp_cum_returns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcumsum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp_returns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m     \u001b[0msig_rets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msig\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mp_returns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m     \u001b[0mcr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcumsum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig_rets\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0msig_rets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (150540,) (150870,) "
          ]
        }
      ]
    }
  ]
}